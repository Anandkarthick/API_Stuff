{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction and load from FRED API.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages for the process... \n",
    "\n",
    "import requests\n",
    "import pickle\n",
    "import os\n",
    "import mysql.connector\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pickle to wrap the database credentials and Fred API keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('fred_api_secret.pk1'):\n",
    "    fred_key = {}\n",
    "    fred_key['api_key'] = ''\n",
    "    with open ('fred_api_secret.pk1','wb') as f:\n",
    "        pickle.dump(fred_key,f)\n",
    "else:\n",
    "    fred_key=pickle.load(open('fred_api_secret.pk1','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('fred_sql.pk1'):\n",
    "    fred_sql = {}\n",
    "    fred_sql['user'] = ''\n",
    "    fred_sql['password'] = ''\n",
    "    fred_sql['database'] = ''\n",
    "    with open ('fred_sql.pk1','wb') as f:\n",
    "        pickle.dump(fred_sql,f)\n",
    "else:\n",
    "    fred_sql=pickle.load(open('fred_sql.pk1','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing database connection.\n",
    "\n",
    "We have a lookup table containing the FRED series along with the value. Let's export the connection parameters and test the connection by running a select query against the lookup table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMCSENT - University of Michigan Consumer Sentiment Index\n",
      "GDPC1 - Real Gross Domestic Product\n",
      "UNRATE - US Civilian Unemployment Rate\n"
     ]
    }
   ],
   "source": [
    "cn = mysql.connector.connect(user=fred_sql['user'], password=fred_sql['password'],\n",
    "                              host='127.0.0.1',\n",
    "                              database=fred_sql['database'])\n",
    "cursor = cn.cursor()\n",
    "\n",
    "query = (\"SELECT frd_cd,frd_val FROM frd_lkp\")\n",
    "cursor.execute(query)\n",
    "\n",
    "for (frd_cd,frd_val) in cursor:\n",
    "    sr_list.append(frd_cd)\n",
    "    print(frd_cd +' - '+ frd_val)\n",
    "\n",
    "cn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions.. \n",
    "\n",
    "We are doing this exercise with minimal modelling. Hence, just one target table to store the observations for all series. \n",
    "\n",
    "Let's create few helper functions to make this process easier. \n",
    "\n",
    "    db_max_count - We are adding surrogate key to the table to make general querying operations and loads easier. COALESCE is used, to get a valid value from the database. \n",
    "\n",
    "    db_srs_count - Since we are using just one target table, we are adding the series name as part of the data. this function will help us with the count for each series present in the table. \n",
    "\n",
    "    fred_req - Helper function that sends the request to FRED API and returns the response back.. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def db_max_count():\n",
    "    cn = mysql.connector.connect(user=fred_sql['user'], password=fred_sql['password'],\n",
    "                              host='127.0.0.1',\n",
    "                              database=fred_sql['database'])\n",
    "    cursor = cn.cursor()\n",
    "    dbquery = (\"SELECT COALESCE(max(idfrd_srs),0) FROM frd_srs_data\")\n",
    "    cursor.execute(dbquery)\n",
    "    \n",
    "    for ct in cursor:\n",
    "        if ct is not None:\n",
    "            return ct[0]\n",
    "    cn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def db_srs_count():\n",
    "    cn = mysql.connector.connect(user=fred_sql['user'], password=fred_sql['password'],\n",
    "                              host='127.0.0.1',\n",
    "                              database=fred_sql['database'])\n",
    "    cursor = cn.cursor()\n",
    "    dbquery = (\"SELECT frd_srs, count(*) FROM frd_srs_data group by frd_srs\")\n",
    "    cursor.execute(dbquery)\n",
    "    \n",
    "    for ct in cursor:\n",
    "        print(ct)\n",
    "    cn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fred_req(series):\n",
    "    time.sleep(10)\n",
    "    response = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id='+series+'&api_key='+fred_key['api_key']+'&file_type=json')\n",
    "    result = response.json()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main functions.. \n",
    "\n",
    "We are creating main functions to support the process. Here are the steps \n",
    "\n",
    "    1) Get the data from FRED API. (helper function created above)\n",
    "    2) Validate and transform the observations data from API.\n",
    "    3) Create tuples according to the table structure. \n",
    "    4) Load the tuples into the relational database\n",
    "    \n",
    "fred_data for Step 2 & Step 3. Function dbload for Step 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dbload(tuple_list):\n",
    "    try:\n",
    "    \n",
    "        cn = mysql.connector.connect(user=fred_sql['user'], password=fred_sql['password'],\n",
    "                                      host='127.0.0.1',\n",
    "                                      database=fred_sql['database'])\n",
    "        cursor = cn.cursor()\n",
    "\n",
    "        insert_query = (\"INSERT INTO frd_srs_data\"\n",
    "                               \"(idfrd_srs,frd_srs,frd_srs_val_dt,frd_srs_val,frd_srs_val_yr,frd_srs_val_mth,frd_srs_val_dy,frd_srs_strt_dt,frd_srs_end_dt)\"\n",
    "                               \"VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)\")\n",
    "\n",
    "        print(\"*** Database Connection Initialized, buckle up the seat belts..\")\n",
    "    \n",
    "        # Data load.. \n",
    "        for i in range(len(tuple_list)):\n",
    "            data_val=tuple_list[i]\n",
    "            cursor.execute(insert_query, data_val)\n",
    "\n",
    "        cn.commit()\n",
    "        \n",
    "        ## Intended timeout before starting the next interation of load..  \n",
    "        time.sleep(5)\n",
    "        \n",
    "        \n",
    "        print(\"\\n *** Data load successful.. \")\n",
    "        db_srs_count()\n",
    "        \n",
    "        # Closing database connection... \n",
    "        cn.close\n",
    "    except mysql.connector.Error as err:\n",
    "        cn.close\n",
    "        print(\"Something went wrong: {}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fred_data(series):\n",
    "    print(\"\\n\")\n",
    "    print(\"** Getting data for the series: \" + series)\n",
    "    \n",
    "    counter=db_max_count()\n",
    "    # Calling function to get the data from FRED API for the series.\n",
    "    fred_result = fred_req(series)\n",
    "    \n",
    "    print(\"** Number of observations extracted -\" '{:d}'.format(fred_result['count']))\n",
    "    \n",
    "    # transforming observations and preparing for data load.\n",
    "    print(\"** Preparing data for load for series -\",series)\n",
    "    temp_lst = fred_result['observations']\n",
    "    tlist = []\n",
    "\n",
    "    # from the incoming data, let's create tuple of values for data load. \n",
    "    for val in range(len(temp_lst)):\n",
    "        temp_dict = temp_lst[val]\n",
    "        for key,val in temp_dict.items():\n",
    "            if key=='date':\n",
    "                dt_lst = val.split(\"-\")\n",
    "                yr  = dt_lst[0]\n",
    "                mth = dt_lst[1]\n",
    "                dtt = dt_lst[2]\n",
    "            if key=='value':\n",
    "                if len(val.strip())>1:\n",
    "                    out_val = val\n",
    "                else:\n",
    "                    out_val = 0.00\n",
    "                counter+=1\n",
    "        tup = (counter,series,temp_dict['date'],out_val,yr,mth,dtt,temp_dict['realtime_start'],temp_dict['realtime_end'])\n",
    "        tlist.append(tup)\n",
    "    print(\"** Data is ready for the load.. Loading \" '{:d}'.format(len(tlist)))\n",
    "    dbload(tlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting point... \n",
    "\n",
    "So, we have all functions created based on few assumptions (that data is all good with very minimal or no issues). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "** Getting data for the series: UMCSENT\n",
      "** Number of observations extracted -574\n",
      "** Preparing data for load for series - UMCSENT\n",
      "** Data is ready for the load.. Loading 574\n",
      "*** Database Connection Initialized, buckle up the seat belts..\n",
      "\n",
      " *** Data load successful.. \n",
      "('UMCSENT', 574)\n",
      "\n",
      "\n",
      "** Getting data for the series: GDPC1\n",
      "** Number of observations extracted -284\n",
      "** Preparing data for load for series - GDPC1\n",
      "** Data is ready for the load.. Loading 284\n",
      "*** Database Connection Initialized, buckle up the seat belts..\n",
      "\n",
      " *** Data load successful.. \n",
      "('GDPC1', 284)\n",
      "('UMCSENT', 574)\n",
      "\n",
      "\n",
      "** Getting data for the series: UNRATE\n",
      "** Number of observations extracted -842\n",
      "** Preparing data for load for series - UNRATE\n",
      "** Data is ready for the load.. Loading 842\n",
      "*** Database Connection Initialized, buckle up the seat belts..\n",
      "\n",
      " *** Data load successful.. \n",
      "('GDPC1', 284)\n",
      "('UMCSENT', 574)\n",
      "('UNRATE', 842)\n"
     ]
    }
   ],
   "source": [
    "sr_list = ['UMCSENT', 'GDPC1', 'UNRATE']\n",
    "\n",
    "for series in sr_list:\n",
    "    fred_data(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 7.175000000000001)\n",
      "(1981, 7.616666666666667)\n",
      "(1982, 9.708333333333332)\n",
      "(1983, 9.6)\n",
      "(1984, 7.508333333333334)\n",
      "(1985, 7.191666666666666)\n",
      "(1986, 7.0)\n",
      "(1987, 6.175000000000001)\n",
      "(1988, 5.491666666666666)\n",
      "(1989, 5.258333333333333)\n",
      "(1990, 5.616666666666666)\n",
      "(1991, 6.849999999999999)\n",
      "(1992, 7.491666666666667)\n",
      "(1993, 6.908333333333332)\n",
      "(1994, 6.1000000000000005)\n",
      "(1995, 5.591666666666668)\n",
      "(1996, 5.408333333333334)\n",
      "(1997, 4.941666666666666)\n",
      "(1998, 4.5)\n",
      "(1999, 4.216666666666668)\n",
      "(2000, 3.9666666666666663)\n",
      "(2001, 4.741666666666666)\n",
      "(2002, 5.783333333333334)\n",
      "(2003, 5.991666666666667)\n",
      "(2004, 5.541666666666667)\n",
      "(2005, 5.083333333333333)\n",
      "(2006, 4.608333333333333)\n",
      "(2007, 4.616666666666667)\n",
      "(2008, 5.8)\n",
      "(2009, 9.283333333333333)\n",
      "(2010, 9.608333333333333)\n",
      "(2011, 8.933333333333334)\n",
      "(2012, 8.075000000000001)\n",
      "(2013, 7.358333333333334)\n",
      "(2014, 6.175000000000001)\n",
      "(2015, 5.266666666666667)\n"
     ]
    }
   ],
   "source": [
    "    cn = mysql.connector.connect(user=fred_sql['user'], password=fred_sql['password'],\n",
    "                              host='127.0.0.1',\n",
    "                              database=fred_sql['database'])\n",
    "    cursor = cn.cursor()\n",
    "    quizquery = (\"SELECT frd_srs_val_yr , avg(frd_srs_val) as avg_unrate FROM fred.frd_srs_data WHERE frd_srs='UNRATE' AND frd_srs_val_yr BETWEEN 1980 AND 2015 GROUP BY  frd_srs_val_yr  ORDER BY 1\")\n",
    "    cursor.execute(quizquery)\n",
    "    \n",
    "    for qz in cursor:\n",
    "        print(qz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
